import re
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from upsetplot import from_indicators, UpSet
import random
import os

#Helper function so save the generated plots
outdir = "pangenome_figures"
os.makedirs(outdir, exist_ok=True)

def save_fig(name):
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, f"{name}.png"), dpi=300)
    plt.show()

# -------------------
# Step 1: Parse .clstr
# -------------------
def parse_clstr(path):
    clusters = {}
    current = None
    with open(path) as f:
        for raw in f:
            line = raw.strip()
            if not line:
                continue
            if line.startswith(">Cluster"):
                current = int(line.split()[1])
                clusters[current] = []
            else:
                # Extract sequence ID (like 245894_CBEc5_03324)
                m = re.search(r">(.*?)\.\.\.", line)
                if not m:
                    continue
                seq_id = m.group(1)
                clusters[current].append(seq_id)
    return clusters

# -------------------
# Step 2: Extract strains
# -------------------
def extract_strain(seq_id):
    # Your IDs look like: 245894_CBEc5_03324
    # We'll take the "CBEc5" part as strain ID
    parts = seq_id.split("_")
    return parts[1] if len(parts) > 1 else seq_id

# -------------------
# Step 3: Build presence/absence matrix
# -------------------
# Automatically find the latest .clstr file generated by workflow1.sh
# Search recursively from the current script's directory

def find_latest_clstr_file(search_root):
    clstr_files = []
    for root, dirs, files in os.walk(search_root):
        for f in files:
            if f.endswith(".clstr"):
                clstr_files.append(os.path.join(root, f))
    if not clstr_files:
        raise FileNotFoundError("No .clstr file found in the directory tree.")
    # Sort by modification time, newest first
    clstr_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    return clstr_files[0]

search_root = os.path.dirname(__file__)
clstr_path = find_latest_clstr_file(search_root)
clusters = parse_clstr(clstr_path)

# Build DataFrame: rows = clusters, cols = strains
strain_set = sorted({extract_strain(s) for seqs in clusters.values() for s in seqs})
presence_absence = pd.DataFrame(0, index=clusters.keys(), columns=strain_set)

for cid, seqs in clusters.items():
    strains = {extract_strain(s) for s in seqs}
    for strain in strains:
        presence_absence.loc[cid, strain] = 1

# -------------------
# Step 4: Visualizations
# -------------------

# -------------------
# 1) presence absence matrix
# Visualize only first N clusters
# -------------------
N = 20  # number of clusters to show
subset = presence_absence.iloc[:N]

plt.figure(figsize=(12,6))
cmap = plt.cm.Blues  # soft color palette

# Display matrix
plt.matshow(subset, fignum=1, cmap=cmap, aspect='auto')

# Colorbar
plt.colorbar(label='Presence (1) / Absence (0)')

# Set ticks
plt.xticks(ticks=np.arange(len(subset.columns)), labels=subset.columns, rotation=90, fontsize=6)
plt.yticks(ticks=np.arange(len(subset.index)), labels=subset.index)

# Add grid lines between cells for clarity
plt.grid(which='both', color='gray', linestyle='-', linewidth=0.5)
plt.title(f"Presence/Absence Matrix for First {N} Clusters", pad=30, fontsize=8)
plt.tight_layout()
save_fig("presence_absence_matrix")


# 2) Histogram of cluster sizes (# of genes per cluster)
cluster_sizes = presence_absence.sum(axis=1)

plt.figure(figsize=(10,6))

# Histogram with nicer aesthetics
counts, bins, patches = plt.hist(
    cluster_sizes,
    bins=range(1, cluster_sizes.max()+2),
    color="#69b3a2",       # soft green
    edgecolor="black",      # bar borders
    alpha=0.85
)
plt.xticks(range(1, cluster_sizes.max()+1), fontsize=8)  # smaller x axis labels

# Add counts on top of bars
for count, patch in zip(counts, patches):
    height = patch.get_height()
    if height > 0:
        plt.text(
            patch.get_x() + patch.get_width()/2,
            height + 5,       # small offset
            int(height),
            ha="center",
            va="bottom",
            fontsize=5
        )

plt.xlabel("Number of strains in cluster", fontsize=8)
plt.ylabel("Number of clusters", fontsize=8)
plt.title("Distribution of Cluster Occupancy Across Strains", fontsize=8)
plt.xticks(range(1, cluster_sizes.max()+1))
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.tight_layout()
save_fig("cluster_size_histogram")

# 3) Bubble chart: cluster size vs number of sequences
num_sequences = [len(clusters[c]) for c in clusters]
strain_counts = cluster_sizes.values
#plt.figure(figsize=(8,6))
#plt.scatter(strain_counts, num_sequences, s=np.array(num_sequences)*10, alpha=0.5)
#plt.xlabel("Number of strains represented")
#plt.ylabel("Number of sequences in cluster")
#plt.title("Bubble Chart: Cluster Size vs Strain Representation")
#plt.tight_layout()
#plt.show()

# 4) Heatmap of pairwise strain similarity (shared clusters)
N = 100  # first N clusters
subset = presence_absence.iloc[:N]  # select first N clusters (rows)

# Compute pairwise strain similarity only for these clusters
strain_similarity_subset = subset.T.dot(subset)

plt.figure(figsize=(8,6))
plt.imshow(strain_similarity_subset, cmap="viridis")
plt.colorbar(label="Shared clusters (first N clusters)")
plt.xticks(range(len(strain_set)), strain_set, rotation=90, fontsize=6)
plt.yticks(range(len(strain_set)), strain_set, fontsize=6)
plt.title(f"Strain Similarity Heatmap (first {N} clusters)")
plt.tight_layout()
save_fig("strain_similarity_heatmap")


# 5) Core vs accessory genome curve
strain_counts_sorted = np.sort(strain_counts)[::-1]
cumulative = np.cumsum(strain_counts_sorted) / np.sum(strain_counts_sorted)
plt.figure(figsize=(8,5))
plt.plot(range(1,len(cumulative)+1), cumulative, marker='o')
plt.xlabel("Clusters (sorted by strain representation)")
plt.ylabel("Cumulative fraction of genes")
plt.title("Core vs Accessory Genome Structure")
plt.grid(True)
plt.tight_layout()
save_fig("core_accessory_curve")


# 6) core and pan-genome accumulation Curves
def core_pan_curve(presence_absence, n_perm=50):
    strains = list(presence_absence.columns)
    n_strains = len(strains)
    core_counts = np.zeros((n_perm, n_strains))
    pan_counts = np.zeros((n_perm, n_strains))
    
    for p in range(n_perm):
        order = random.sample(strains, len(strains))  # random order of strains
        current_pan = set()
        current_core = set(presence_absence.index)  # start with all clusters
        
        for i, strain in enumerate(order):
            # clusters present in this strain
            strain_clusters = set(presence_absence.index[presence_absence[strain] == 1])
            
            # update pan-genome
            current_pan |= strain_clusters
            pan_counts[p, i] = len(current_pan)
            
            # update core-genome
            current_core &= strain_clusters
            core_counts[p, i] = len(current_core)
    
    # Average across permutations
    mean_pan = pan_counts.mean(axis=0)
    mean_core = core_counts.mean(axis=0)
    return mean_core, mean_pan

# Run curves
mean_core, mean_pan = core_pan_curve(presence_absence, n_perm=100)

# Plot
plt.figure(figsize=(8,6))
x = range(1, len(mean_core)+1)
plt.plot(x, mean_pan, marker='o', label="Pan-genome size")
plt.plot(x, mean_core, marker='o', label="Core-genome size")
plt.xlabel("Number of genomes added")
plt.ylabel("Number of gene clusters")
plt.title("Core and Pan-genome Accumulation Curves")
plt.legend()
plt.grid(True)
plt.tight_layout()
save_fig("core_pan_genome_curves")


# -------------------
# Parse .clstr for hybrid stacked bar
# -------------------
def parse_clstr_for_stacked_bar(path):
    reps = {}     # cluster -> (strain, length)
    strain_map = {}  # cluster -> list of strains in cluster
    current = None
    with open(path) as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith(">Cluster"):
                current = int(line.split()[1])
                strain_map[current] = set()
            else:
                m = re.match(r"\d+\s+(\d+)aa,\s+>([^.]+).*?(\*)?$", line)
                if m:
                    length = int(m.group(1))
                    seq_id = m.group(2)
                    strain = extract_strain(seq_id)
                    strain_map[current].add(strain)
                    if m.group(3) == '*':  # representative
                        reps[current] = (strain, length)
    return reps, strain_map

# -------------------
# Build stacked bar DataFrame
# -------------------
N = 20  # first N clusters
reps, strain_map = parse_clstr_for_stacked_bar(clstr_path)
first_clusters = list(reps.keys())[:N]

# Build DataFrame: rows=clusters, cols=strains
all_strains = sorted({s for strains in strain_map.values() for s in strains})
df = pd.DataFrame(0, index=first_clusters, columns=all_strains, dtype=float)

for cid in first_clusters:
    rep_strain, rep_len = reps[cid]
    strains = strain_map[cid]
    for s in strains:
        df.loc[cid, s] = rep_len / len(strains)  # split rep length among strains

# -------------------
# Plot stacked bar
# -------------------
ax = df.plot(kind="bar", stacked=True, figsize=(14,6), colormap="tab20")
ax.set_xlabel("Cluster ID")
ax.set_ylabel("Representative sequence length (aa)")
ax.set_title(f"First {N} clusters with strain contributions")
plt.legend(title="Strain", bbox_to_anchor=(1.05,1), loc="upper left")
plt.tight_layout()
save_fig("stacked_bar_clusters")